{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import os\n",
    "import pandas\n",
    "import re\n",
    "import glob\n",
    "import joblib\n",
    "import numpy\n",
    "import math\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction(object):\n",
    "    def __init__(self):\n",
    "        self.model_list = []\n",
    "        self.score = None\n",
    "        self.x = 0\n",
    "        self.frame = None\n",
    "        self.column = 0\n",
    "        self.row = 0\n",
    "    \n",
    "    def ModelLoading(self):\n",
    "        model_dir = os.path.join(os.getcwd(), \"models\")\n",
    "        files = glob.glob(os.path.join(model_dir, \"*.pkl\"))\n",
    "        self.model_list = []\n",
    "        for file in files:\n",
    "            with open(file, 'rb') as f:\n",
    "                load_model = joblib.load(f)\n",
    "                self.model_list.append(load_model)\n",
    "    \n",
    "    def ModelPrediction(self):\n",
    "        prediction_score = None\n",
    "        for model in self.model_list:\n",
    "            try:\n",
    "                temp = model.predict_proba(self.frame.values)\n",
    "            except AttributeError:\n",
    "                temp = model.predict(self.frame.values)\n",
    "            if prediction_score is None:\n",
    "                prediction_score = temp\n",
    "            else:\n",
    "                prediction_score += temp\n",
    "            \n",
    "        prediction_score /= len(self.model_list)\n",
    "        if self.score is None:\n",
    "                self.score = prediction_score\n",
    "        else:\n",
    "            self.score += prediction_score\n",
    "    \n",
    "    def DataLoading(self, file):\n",
    "        f = pandas.read_csv(file, sep=',', header=None)\n",
    "        self.frame = f.iloc[:, 1:]\n",
    "        self.row = self.frame.index.size\n",
    "        self.column = self.frame.columns.size\n",
    "        self.frame.index=['Sample_%s'%i for i in range(self.row)]\n",
    "        self.frame.columns = ['F_%s'%i for i in range(self.column)]\n",
    "        self.label = numpy.array(f.iloc[:, 0]).astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FeatureExtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FASTA(object):\n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    "        self.fasta_list = []\n",
    "        self.number = 0\n",
    "        self.encoding_array = numpy.array([])\n",
    "        self.row = 0\n",
    "        self.column = 0\n",
    "\n",
    "        self.fasta_list = self.read_fasta(self.file)\n",
    "        self.number = len(self.fasta_list)\n",
    "\n",
    "    def read_fasta(self, file):\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "        text = text.split('>')[1:]\n",
    "        fasta_sequences = []\n",
    "        for fasta in text:\n",
    "            array = fasta.split('\\n')\n",
    "            header = array[0].split()[0]\n",
    "            header_array = header.split('|')\n",
    "            sequence = re.sub('[^ACDEFGHIKLMNPQRSTVWY-]', '-', ''.join(array[1:]).upper())\n",
    "            name = header_array[0]\n",
    "            label = header_array[1]\n",
    "            train = header_array[2]\n",
    "            fasta_sequences.append([name, sequence, label, train])\n",
    "        return fasta_sequences\n",
    "    \n",
    "    def save(self, FileName):\n",
    "        file = self.encoding_array\n",
    "        file_save = file[:, 1:]\n",
    "        numpy.savetxt(FileName, file_save, fmt='%s', delimiter=',')\n",
    "\n",
    "class AAC(FASTA):\n",
    "    def __init__(self, file):\n",
    "        super(AAC, self).__init__(file)\n",
    "\n",
    "    def AAC(self):\n",
    "        AA = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "        encodings = []\n",
    "        self.encoding_array = numpy.array([])\n",
    "        header = ['Name', 'label']\n",
    "        for i in AA:\n",
    "            header.append(i)\n",
    "        encodings.append(header)\n",
    "\n",
    "        for k in self.fasta_list:\n",
    "            name = k[0]\n",
    "            sequence = re.sub('-', '' , k[1])\n",
    "            label = k[2]\n",
    "            code = [name, label]\n",
    "            occur = Counter(sequence)\n",
    "            sum = len(sequence)\n",
    "            for i in AA:\n",
    "                code.append(occur[i] / sum)   \n",
    "            encodings.append(code)\n",
    "\n",
    "        self.encoding_array = numpy.array(encodings, dtype=str)\n",
    "        self.row = self.encoding_array[0]\n",
    "        self.column = self.encoding_array[1]\n",
    "        del encodings\n",
    "    \n",
    "class CKSAAP(FASTA):\n",
    "    def __init__(self, file):\n",
    "        super(CKSAAP, self).__init__(file)\n",
    "\n",
    "    def CKSAAP(self):\n",
    "        gap = 3\n",
    "        AA = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "        encodings = []\n",
    "        AA_Pairs = []\n",
    "        self.encoding_array = numpy.array([])\n",
    "        for i in AA:\n",
    "            for j in AA:\n",
    "                AA_Pairs.append(i + j)\n",
    "        header = ['Name', 'label']\n",
    "        for g in range(gap + 1):\n",
    "            for i in AA_Pairs:\n",
    "                header.append(i + '.gap' + str(g))\n",
    "        encodings.append(header)\n",
    "\n",
    "        for k in self.fasta_list:\n",
    "            name = k[0]\n",
    "            sequence = re.sub('-', '' , k[1])\n",
    "            label = k[2]\n",
    "            code = [name, label]\n",
    "            for g in range(gap + 1):\n",
    "                occur = {}\n",
    "                for pair in AA_Pairs:\n",
    "                    occur[pair] = 0\n",
    "                for i in range(len(sequence) - g - 1):\n",
    "                    j = i + g + 1\n",
    "                    occur[sequence[i] + sequence[j]] += 1\n",
    "                for pair in AA_Pairs:\n",
    "                    code.append(occur[pair] / (len(sequence) - g - 1))\n",
    "            encodings.append(code)\n",
    "\n",
    "        self.encoding_array = numpy.array(encodings, dtype=str)\n",
    "        self.row = self.encoding_array[0]\n",
    "        self.column = self.encoding_array[1]\n",
    "        del encodings\n",
    "\n",
    "class DDE(FASTA):\n",
    "    def __init__(self, file):\n",
    "        super(DDE, self).__init__(file)\n",
    "    \n",
    "    def DDE(self):\n",
    "        AA = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "        encodings = []\n",
    "        AA_Pairs = []\n",
    "        self.encoding_array = numpy.array([])\n",
    "        for i in AA:\n",
    "            for j in AA:\n",
    "                AA_Pairs.append(i + j)\n",
    "        header = ['Name', 'label'] + AA_Pairs\n",
    "        encodings.append(header)\n",
    "        Codons = {'A': 4, 'C': 2, 'D': 2, 'E': 2, 'F': 2, 'G': 4, 'H': 2, 'I': 3, 'K': 2, 'L': 6, \n",
    "                  'M': 1, 'N': 2, 'P': 4, 'Q': 2, 'R': 6, 'S': 6, 'T': 4, 'V': 4, 'W': 1, 'Y': 2}\n",
    "        \n",
    "        Tm = []\n",
    "        for i in AA_Pairs:\n",
    "            Tm.append((Codons[i[0]] / 61) * (Codons[i[1]] / 61))\n",
    "        \n",
    "        for k in self.fasta_list:\n",
    "            name = k[0]\n",
    "            sequence = re.sub('-', '' , k[1])\n",
    "            label = k[2]\n",
    "            code = [name, label]\n",
    "            temp = []\n",
    "            occur = {}\n",
    "            for pair in AA_Pairs:\n",
    "                occur[pair] = 0\n",
    "            for i in range(len(sequence) - 1):\n",
    "                occur[sequence[i] + sequence[i + 1]] += 1\n",
    "            for pair in AA_Pairs:\n",
    "                temp.append(occur[pair] / (len(sequence) - 1))\n",
    "\n",
    "            Tv = []\n",
    "            for i in range(len(Tm)):\n",
    "                Tv.append(Tm[i] * (1- Tm[i]) / (len(sequence) - 1))\n",
    "\n",
    "            for i in range(len(temp)):\n",
    "                temp[i] = (temp[i] - Tm[i]) / math.sqrt(Tv[i])\n",
    "            code = code +temp\n",
    "            encodings.append(code)\n",
    "\n",
    "        self.encoding_array = numpy.array(encodings, dtype=str)\n",
    "        self.row = self.encoding_array[0]\n",
    "        self.column = self.encoding_array[1]\n",
    "        del encodings\n",
    "\n",
    "class APAAC(FASTA):\n",
    "    def __init__(self, file):\n",
    "        super(APAAC, self).__init__(file)\n",
    "    \n",
    "    def APAAC(self):\n",
    "        lambdaValue = 2\n",
    "        w = 0.05\n",
    "        dataFile = os.path.join(os.getcwd(), 'data', 'PAAC.txt')\n",
    "        with open(dataFile) as f:\n",
    "            PAAC = f.readlines()\n",
    "\n",
    "        AA = ''.join(PAAC[0].rstrip().split()[1:])\n",
    "        dict = {}\n",
    "        prop1 = []\n",
    "        name = []\n",
    "        encodings = []\n",
    "        self.encoding_array = numpy.array([])\n",
    "        header = ['Name', 'label']\n",
    "        for i in range(len(AA)):\n",
    "            dict[AA[i]] = i\n",
    "        for i in range(1, len(PAAC) - 1):\n",
    "            array = PAAC[i].rstrip().split() if PAAC[i].rstrip() != '' else None\n",
    "            prop1.append([float(j) for j in array[1:]])\n",
    "            name.append(array[0])\n",
    "        for i in AA:\n",
    "            header.append('Pc1.' + i)\n",
    "        for j in range(1, lambdaValue + 1):\n",
    "            for i in name:\n",
    "                header.append('Pc2.' + i + '.' + str(j))\n",
    "        encodings.append(header)\n",
    "        \n",
    "        prop2 = []\n",
    "        for i in prop1:\n",
    "            mean = sum(i) / 20\n",
    "            den = math.sqrt(sum([(j - mean) ** 2 for j in i]) / 20)\n",
    "            prop2.append([(j - mean) / den for j in i])\n",
    "        \n",
    "        for k in self.fasta_list:\n",
    "            name = k[0]\n",
    "            sequence = re.sub('-', '' , k[1])\n",
    "            label = k[2]\n",
    "            code = [name, label]\n",
    "            theta = []\n",
    "            for n in range(1, lambdaValue + 1):\n",
    "                for i in range(len(prop2)):\n",
    "                    theta.append(sum([prop2[i][dict[sequence[j]]] * prop2[i][dict[sequence[j + n]]] for j in range(len(sequence) - n)]) / (len(sequence) - n))\n",
    "            \n",
    "            occur = {}\n",
    "            for i in AA:\n",
    "                occur[i] = sequence.count(i)\n",
    "            for i in AA:\n",
    "                code = code + [occur[i] / (1 + w * sum(theta))]\n",
    "            for i in theta:\n",
    "                code = code + [w * i / (1 + w * sum(theta))]\n",
    "            encodings.append(code)\n",
    "        \n",
    "        self.encoding_array = numpy.array(encodings, dtype=str)\n",
    "        self.row = self.encoding_array.shape[0]\n",
    "        self.column = self.encoding_array.shape[1]\n",
    "        del encodings\n",
    "\n",
    "class ASDC(FASTA):\n",
    "    def __init__(self, file):\n",
    "        super(ASDC, self).__init__(file)\n",
    "\n",
    "    def ASDC(self):\n",
    "        AA = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "        encodings = []\n",
    "        AA_Pairs = []\n",
    "        self.encoding_array = numpy.array([])\n",
    "        for i in AA:\n",
    "            for j in AA:\n",
    "                AA_Pairs.append(i + j)\n",
    "        header = ['Name', 'label'] + AA_Pairs\n",
    "        encodings.append(header)\n",
    "\n",
    "        for k in self.fasta_list:\n",
    "            name = k[0]\n",
    "            sequence = re.sub('-', '' , k[1])\n",
    "            label = k[2]\n",
    "            code = [name, label]\n",
    "            occur = {}\n",
    "            sum = 0\n",
    "            for i in AA_Pairs:\n",
    "                occur[i] = 0\n",
    "            for i in range(len(sequence) - 1):\n",
    "                for j in range(i + 1, len(sequence)):\n",
    "                    occur[sequence[i] + sequence[j]] += 1\n",
    "                    sum += 1\n",
    "            for i in AA_Pairs:\n",
    "                code.append(occur[i] / sum)\n",
    "            encodings.append(code)\n",
    "\n",
    "        self.encoding_array = numpy.array(encodings, dtype=str)\n",
    "        self.row = self.encoding_array.shape[0]\n",
    "        self.column = self.encoding_array.shape[1]\n",
    "        del encodings\n",
    "\n",
    "class CTDC(FASTA):\n",
    "    def __init__(self, file):\n",
    "        super(CTDC, self).__init__(file)\n",
    "    \n",
    "    def Count_C(self, s, t):\n",
    "        sum = 0\n",
    "        for i in s:\n",
    "            sum = sum + t.count(i)\n",
    "        return sum\n",
    "    \n",
    "    def CTDC(self):\n",
    "        group1 = {\n",
    "            'hydrophobicity_PRAM900101': 'RKEDQN',\n",
    "            'hydrophobicity_ARGP820101': 'QSTNGDE',\n",
    "            'hydrophobicity_ZIMJ680101': 'QNGSWTDERA',\n",
    "            'hydrophobicity_PONP930101': 'KPDESNQT',\n",
    "            'hydrophobicity_CASG920101': 'KDEQPSRNTG',\n",
    "            'hydrophobicity_ENGD860101': 'RDKENQHYP',\n",
    "            'hydrophobicity_FASG890101': 'KERSQD',\n",
    "            'normwaalsvolume': 'GASTPDC',\n",
    "            'polarity': 'LIFWCMVY',\n",
    "            'polarizability': 'GASDT',\n",
    "            'charge': 'KR',\n",
    "            'secondarystruct': 'EALMQKRH',\n",
    "            'solventaccess': 'ALFCGIVW'\n",
    "        }\n",
    "        group2 = {\n",
    "            'hydrophobicity_PRAM900101': 'GASTPHY',\n",
    "            'hydrophobicity_ARGP820101': 'RAHCKMV',\n",
    "            'hydrophobicity_ZIMJ680101': 'HMCKV',\n",
    "            'hydrophobicity_PONP930101': 'GRHA',\n",
    "            'hydrophobicity_CASG920101': 'AHYMLV',\n",
    "            'hydrophobicity_ENGD860101': 'SGTAW',\n",
    "            'hydrophobicity_FASG890101': 'NTPG',\n",
    "            'normwaalsvolume': 'NVEQIL',\n",
    "            'polarity': 'PATGS',\n",
    "            'polarizability': 'CPNVEQIL',\n",
    "            'charge': 'ANCQGHILMFPSTWYV',\n",
    "            'secondarystruct': 'VIYCWFT',\n",
    "            'solventaccess': 'RKQEND'\n",
    "        }\n",
    "        group3 = {\n",
    "            'hydrophobicity_PRAM900101': 'CLVIMFW',\n",
    "            'hydrophobicity_ARGP820101': 'LYPFIW',\n",
    "            'hydrophobicity_ZIMJ680101': 'LPFYI',\n",
    "            'hydrophobicity_PONP930101': 'YMFWLCVI',\n",
    "            'hydrophobicity_CASG920101': 'FIWC',\n",
    "            'hydrophobicity_ENGD860101': 'CVLIMF',\n",
    "            'hydrophobicity_FASG890101': 'AYHWVMFLIC',\n",
    "            'normwaalsvolume': 'MHKFRYW',\n",
    "            'polarity': 'HQRKNED',\n",
    "            'polarizability': 'KMHFRYW',\n",
    "            'charge': 'DE',\n",
    "            'secondarystruct': 'GNPSD',\n",
    "            'solventaccess': 'MSPTHY'\n",
    "        }\n",
    "        groups = [group1, group2, group3]\n",
    "        property = (\n",
    "            'hydrophobicity_PRAM900101', 'hydrophobicity_ARGP820101', 'hydrophobicity_ZIMJ680101',\n",
    "            'hydrophobicity_PONP930101',\n",
    "            'hydrophobicity_CASG920101', 'hydrophobicity_ENGD860101', 'hydrophobicity_FASG890101', 'normwaalsvolume',\n",
    "            'polarity', 'polarizability', 'charge', 'secondarystruct', 'solventaccess')\n",
    "        self.encoding_array = numpy.array([])\n",
    "        encodings = []\n",
    "        header = ['Name', 'label']\n",
    "        for i in property:\n",
    "            for j in range(1, len(groups) + 1):\n",
    "                header.append(i + '.G' + str(j))\n",
    "        encodings.append(header)\n",
    "\n",
    "        for k in self.fasta_list:\n",
    "            name = k[0]\n",
    "            sequence = re.sub('-', '' , k[1])\n",
    "            label = k[2]\n",
    "            code = [name, label]\n",
    "            for i in property:\n",
    "                c1 = self.Count_C(group1[i], sequence) / len(sequence)\n",
    "                c2 = self.Count_C(group2[i], sequence) / len(sequence)\n",
    "                c3 = 1 - c1 - c2\n",
    "                code = code + [c1, c2, c3]\n",
    "            encodings.append(code)\n",
    "        \n",
    "        self.encoding_array = numpy.array(encodings, dtype=str)\n",
    "        self.row = self.encoding_array.shape[0]\n",
    "        self.column = self.encoding_array.shape[1]\n",
    "        del encodings\n",
    "\n",
    "class CTDT(FASTA):\n",
    "    def __init__(self, file):\n",
    "        super(CTDT, self).__init__(file)\n",
    "    \n",
    "    def CTDT(self):\n",
    "        group1 = {\n",
    "            'hydrophobicity_PRAM900101': 'RKEDQN',\n",
    "            'hydrophobicity_ARGP820101': 'QSTNGDE',\n",
    "            'hydrophobicity_ZIMJ680101': 'QNGSWTDERA',\n",
    "            'hydrophobicity_PONP930101': 'KPDESNQT',\n",
    "            'hydrophobicity_CASG920101': 'KDEQPSRNTG',\n",
    "            'hydrophobicity_ENGD860101': 'RDKENQHYP',\n",
    "            'hydrophobicity_FASG890101': 'KERSQD',\n",
    "            'normwaalsvolume': 'GASTPDC',\n",
    "            'polarity': 'LIFWCMVY',\n",
    "            'polarizability': 'GASDT',\n",
    "            'charge': 'KR',\n",
    "            'secondarystruct': 'EALMQKRH',\n",
    "            'solventaccess': 'ALFCGIVW'\n",
    "        }\n",
    "        group2 = {\n",
    "            'hydrophobicity_PRAM900101': 'GASTPHY',\n",
    "            'hydrophobicity_ARGP820101': 'RAHCKMV',\n",
    "            'hydrophobicity_ZIMJ680101': 'HMCKV',\n",
    "            'hydrophobicity_PONP930101': 'GRHA',\n",
    "            'hydrophobicity_CASG920101': 'AHYMLV',\n",
    "            'hydrophobicity_ENGD860101': 'SGTAW',\n",
    "            'hydrophobicity_FASG890101': 'NTPG',\n",
    "            'normwaalsvolume': 'NVEQIL',\n",
    "            'polarity': 'PATGS',\n",
    "            'polarizability': 'CPNVEQIL',\n",
    "            'charge': 'ANCQGHILMFPSTWYV',\n",
    "            'secondarystruct': 'VIYCWFT',\n",
    "            'solventaccess': 'RKQEND'\n",
    "        }\n",
    "        group3 = {\n",
    "            'hydrophobicity_PRAM900101': 'CLVIMFW',\n",
    "            'hydrophobicity_ARGP820101': 'LYPFIW',\n",
    "            'hydrophobicity_ZIMJ680101': 'LPFYI',\n",
    "            'hydrophobicity_PONP930101': 'YMFWLCVI',\n",
    "            'hydrophobicity_CASG920101': 'FIWC',\n",
    "            'hydrophobicity_ENGD860101': 'CVLIMF',\n",
    "            'hydrophobicity_FASG890101': 'AYHWVMFLIC',\n",
    "            'normwaalsvolume': 'MHKFRYW',\n",
    "            'polarity': 'HQRKNED',\n",
    "            'polarizability': 'KMHFRYW',\n",
    "            'charge': 'DE',\n",
    "            'secondarystruct': 'GNPSD',\n",
    "            'solventaccess': 'MSPTHY'\n",
    "        }\n",
    "        groups = [group1, group2, group3]\n",
    "        property = (\n",
    "            'hydrophobicity_PRAM900101', 'hydrophobicity_ARGP820101', 'hydrophobicity_ZIMJ680101',\n",
    "            'hydrophobicity_PONP930101',\n",
    "            'hydrophobicity_CASG920101', 'hydrophobicity_ENGD860101', 'hydrophobicity_FASG890101', 'normwaalsvolume',\n",
    "            'polarity', 'polarizability', 'charge', 'secondarystruct', 'solventaccess')\n",
    "        self.encoding_array = numpy.array([])\n",
    "        encodings = []\n",
    "        header = ['Name', 'label']\n",
    "        for i in property:\n",
    "            for j in ('Tr1221', 'Tr1331', 'Tr2332'):\n",
    "                header.append(i + '.' + j)\n",
    "        encodings.append(header)\n",
    "\n",
    "        for k in self.fasta_list:\n",
    "            name = k[0]\n",
    "            sequence = re.sub('-', '' , k[1])\n",
    "            label = k[2]\n",
    "            code = [name, label]\n",
    "            for i in range(len(sequence) - 1):\n",
    "                AA_Pair = [sequence[i:i + 2]]\n",
    "            for i in property:\n",
    "                c1221 = c1331 = c2332 = 0\n",
    "                for AA in AA_Pair:\n",
    "                    if((AA[0] in group1[i]) and (AA[1] in group2[i])):\n",
    "                        c1221 += 1\n",
    "                        continue\n",
    "                    if((AA[0] in group2[i]) and (AA[1] in group1[i])):\n",
    "                        c1221 += 1\n",
    "                        continue\n",
    "                    if((AA[0] in group1[i]) and (AA[1] in group3[i])):\n",
    "                        c1331 += 1\n",
    "                        continue\n",
    "                    if((AA[0] in group3[i]) and (AA[1] in group1[i])):\n",
    "                        c1331 += 1\n",
    "                        continue\n",
    "                    if((AA[0] in group2[i]) and (AA[1] in group3[i])):\n",
    "                        c2332 += 1\n",
    "                        continue\n",
    "                    if((AA[0] in group3[i]) and (AA[1] in group2[i])):\n",
    "                        c2332 += 1\n",
    "                        continue\n",
    "                code = code + [c1221 / len(AA_Pair), c1331 / len(AA_Pair), c2332 / len(AA_Pair)]\n",
    "            encodings.append(code)\n",
    "\n",
    "        self.encoding_array = numpy.array(encodings, dtype=str)\n",
    "        self.row = self.encoding_array.shape[0]\n",
    "        self.column = self.encoding_array.shape[1]\n",
    "        del encodings\n",
    "\n",
    "class CTDD(FASTA):\n",
    "    def __init__(self, file):\n",
    "        super(CTDD, self).__init__(file)\n",
    "    \n",
    "    def Count_D(self, group, s):\n",
    "        sum = 0\n",
    "        for i in s:\n",
    "            if i in group:\n",
    "                sum += 1\n",
    "        node = [1, math.floor(0.25 * sum), math.floor(0.5 * sum), math.floor(0.75 * sum), sum]\n",
    "        node = [i if i >= 1 else 1 for i in node]\n",
    "        \n",
    "        code = []\n",
    "        for n in node:\n",
    "            sum = 0\n",
    "            for i in range(len(s)):\n",
    "                if s[i] in group:\n",
    "                    sum += 1\n",
    "                    if sum == n:\n",
    "                        code.append((i + 1) / len(s) * 100)\n",
    "                        break\n",
    "            if sum == 0:\n",
    "                code.append(0)\n",
    "        return code \n",
    "\n",
    "    def CTDD(self):\n",
    "        group1 = {\n",
    "            'hydrophobicity_PRAM900101': 'RKEDQN',\n",
    "            'hydrophobicity_ARGP820101': 'QSTNGDE',\n",
    "            'hydrophobicity_ZIMJ680101': 'QNGSWTDERA',\n",
    "            'hydrophobicity_PONP930101': 'KPDESNQT',\n",
    "            'hydrophobicity_CASG920101': 'KDEQPSRNTG',\n",
    "            'hydrophobicity_ENGD860101': 'RDKENQHYP',\n",
    "            'hydrophobicity_FASG890101': 'KERSQD',\n",
    "            'normwaalsvolume': 'GASTPDC',\n",
    "            'polarity': 'LIFWCMVY',\n",
    "            'polarizability': 'GASDT',\n",
    "            'charge': 'KR',\n",
    "            'secondarystruct': 'EALMQKRH',\n",
    "            'solventaccess': 'ALFCGIVW'\n",
    "        }\n",
    "        group2 = {\n",
    "            'hydrophobicity_PRAM900101': 'GASTPHY',\n",
    "            'hydrophobicity_ARGP820101': 'RAHCKMV',\n",
    "            'hydrophobicity_ZIMJ680101': 'HMCKV',\n",
    "            'hydrophobicity_PONP930101': 'GRHA',\n",
    "            'hydrophobicity_CASG920101': 'AHYMLV',\n",
    "            'hydrophobicity_ENGD860101': 'SGTAW',\n",
    "            'hydrophobicity_FASG890101': 'NTPG',\n",
    "            'normwaalsvolume': 'NVEQIL',\n",
    "            'polarity': 'PATGS',\n",
    "            'polarizability': 'CPNVEQIL',\n",
    "            'charge': 'ANCQGHILMFPSTWYV',\n",
    "            'secondarystruct': 'VIYCWFT',\n",
    "            'solventaccess': 'RKQEND'\n",
    "        }\n",
    "        group3 = {\n",
    "            'hydrophobicity_PRAM900101': 'CLVIMFW',\n",
    "            'hydrophobicity_ARGP820101': 'LYPFIW',\n",
    "            'hydrophobicity_ZIMJ680101': 'LPFYI',\n",
    "            'hydrophobicity_PONP930101': 'YMFWLCVI',\n",
    "            'hydrophobicity_CASG920101': 'FIWC',\n",
    "            'hydrophobicity_ENGD860101': 'CVLIMF',\n",
    "            'hydrophobicity_FASG890101': 'AYHWVMFLIC',\n",
    "            'normwaalsvolume': 'MHKFRYW',\n",
    "            'polarity': 'HQRKNED',\n",
    "            'polarizability': 'KMHFRYW',\n",
    "            'charge': 'DE',\n",
    "            'secondarystruct': 'GNPSD',\n",
    "            'solventaccess': 'MSPTHY'\n",
    "        }\n",
    "        groups = [group1, group2, group3]\n",
    "        property = (\n",
    "            'hydrophobicity_PRAM900101', 'hydrophobicity_ARGP820101', 'hydrophobicity_ZIMJ680101',\n",
    "            'hydrophobicity_PONP930101',\n",
    "            'hydrophobicity_CASG920101', 'hydrophobicity_ENGD860101', 'hydrophobicity_FASG890101', 'normwaalsvolume',\n",
    "            'polarity', 'polarizability', 'charge', 'secondarystruct', 'solventaccess')\n",
    "        self.encoding_array = numpy.array([])\n",
    "        encodings = []\n",
    "        header = ['Name', 'label']\n",
    "        for i in property:\n",
    "            for j in ('1', '2', '3'):\n",
    "                for k in ['0', '25', '50', '75', '100']:\n",
    "                    header.append(i + '.' + j + '.residue' + k)\n",
    "        encodings.append(header)\n",
    "\n",
    "        for k in self.fasta_list:\n",
    "            name = k[0]\n",
    "            sequence = re.sub('-', '' , k[1])\n",
    "            label = k[2]\n",
    "            code = [name, label]\n",
    "            for i in property:\n",
    "                code = code + self.Count_D(group1[i], sequence) + self.Count_D(group2[i], sequence) + self.Count_D(group3[i], sequence)\n",
    "            encodings.append(code)\n",
    "\n",
    "        self.encoding_array = numpy.array(encodings, dtype=str)\n",
    "        self.row = self.encoding_array.shape[0]\n",
    "        self.column = self.encoding_array.shape[1]\n",
    "        del encodings\n",
    "\n",
    "class QSO(FASTA):\n",
    "    def __init__(self, file):\n",
    "        super(QSO, self).__init__(file)\n",
    "    \n",
    "    def QSO(self):\n",
    "        nlag = 2\n",
    "        w = 0.05\n",
    "        dataFile_S = os.path.join(os.getcwd(), 'data', 'Schneider-Wrede.txt')\n",
    "        dataFile_G = os.path.join(os.getcwd(), 'data', 'Grantham.txt')\n",
    "        AA1 = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "        AA2 = 'ARNDCQEGHILKMFPSTWYV'\n",
    "        self.encoding_array = numpy.array([])\n",
    "        dict_S = {}\n",
    "        dict_G = {}\n",
    "        for i in range(len(AA1)):\n",
    "            dict_S[AA1[i]] = i\n",
    "            dict_G[AA2[i]] = i            \n",
    "        \n",
    "        with open(dataFile_S) as f:\n",
    "            text = f.readlines()[1:]\n",
    "        distance_S = []\n",
    "        for i in text:\n",
    "            array = i.rstrip().split()[1:] if i.rstrip() != '' else None\n",
    "            distance_S.append(array)\n",
    "        distance_S = numpy.array([float(distance_S[i][j]) for i in range(len(distance_S)) for j in range(len(distance_S[i]))]).reshape((20, 20))\n",
    "        \n",
    "        with open(dataFile_G) as f:\n",
    "            text = f.readlines()[1:]\n",
    "        distance_G = []\n",
    "        for i in text:\n",
    "            array = i.rstrip().split()[1:] if i.rstrip() != '' else None\n",
    "            distance_G.append(array)\n",
    "        distance_G = numpy.array([float(distance_G[i][j]) for i in range(len(distance_G)) for j in range(len(distance_G[i]))]).reshape((20, 20))\n",
    "        \n",
    "        encodings = []\n",
    "        header = ['Name', 'label']\n",
    "        for a in AA1:\n",
    "            header.append('Schneider-Wrede.Xr.' + a)\n",
    "        for a in AA2:\n",
    "            header.append('Grantham.Xr.' + a)\n",
    "        for n in range(1, nlag + 1):\n",
    "            header.append('Schneider-Wrede.Xd.' + str(n))\n",
    "        for n in range(1, nlag + 1):\n",
    "            header.append('Grantham.Xd.' + str(n))\n",
    "        encodings.append(header)\n",
    "\n",
    "        for k in self.fasta_list:\n",
    "            name = k[0]\n",
    "            sequence = re.sub('-', '' , k[1])\n",
    "            label = k[2]\n",
    "            code = [name, label]\n",
    "            array_S = []\n",
    "            array_G = []\n",
    "            for n in range(1, nlag + 1):\n",
    "                array_S.append(sum([distance_S[dict_S[sequence[i]]][dict_S[sequence[i + n]]] ** 2 for i in range(len(sequence) - n)]))\n",
    "                array_G.append(sum([distance_G[dict_G[sequence[i]]][dict_G[sequence[i + n]]] ** 2 for i in range(len(sequence) - n)]))\n",
    "            \n",
    "            occur = {}\n",
    "            for a in AA2:\n",
    "                occur[a] = sequence.count(a)\n",
    "            for a in AA2:\n",
    "                code.append(occur[a] / (1 + w * sum(array_S)))\n",
    "            for a in AA2:\n",
    "                code.append(occur[a] / (1 + w * sum(array_G)))\n",
    "            for i in array_S:\n",
    "                code.append((w * i) / (1 + w * sum(array_S)))\n",
    "            for i in array_G:\n",
    "                code.append((w * i) / (1 + w * sum(array_G)))\n",
    "            encodings.append(code)\n",
    "\n",
    "        self.encoding_array = numpy.array(encodings, dtype=str)\n",
    "        self.row = self.encoding_array.shape[0]\n",
    "        self.column = self.encoding_array.shape[1]\n",
    "        del encodings\n",
    "\n",
    "def FeatureMerge():\n",
    "    file_list = [f for f in os.listdir('.') if f.endswith('.csv')]\n",
    "    f = pandas.read_csv(file_list[0])\n",
    "\n",
    "    for file_name in file_list[1:]:\n",
    "        temp = pandas.read_csv(file_name, usecols=lambda col: col not in f.columns[:2])\n",
    "        f = pandas.concat([f, temp], axis=1)\n",
    "\n",
    "    f.to_csv('Merge.csv', header=False, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FeatureSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analysis(object):\n",
    "    def __init__(self):\n",
    "        self.frame = None\n",
    "        self.label = None\n",
    "        self.column = 0\n",
    "        self.row = 0\n",
    "        self.result = None\n",
    "        self.data = None\n",
    "        self.sample = None\n",
    "\n",
    "    def data_import(self, file):\n",
    "        f = pandas.read_csv(file, sep=',', header=None)\n",
    "        self.frame = f.iloc[:, 1:]\n",
    "        self.row = self.frame.index.size\n",
    "        self.column = self.frame.columns.size\n",
    "        self.frame.index=['Sample_%s'%i for i in range(self.row)]\n",
    "        self.frame.columns = ['F_%s'%i for i in range(self.column)]\n",
    "        self.label = numpy.array(f.iloc[:, 0]).astype(int)\n",
    "        self.sample = numpy.array([True] * self.row)\n",
    "\n",
    "def select(x):\n",
    "    path_b = os.path.join('models', 'header.csv')\n",
    "    with open('MergeIG.csv') as a_file, open(path_b) as b_file:\n",
    "        a_reader = csv.reader(a_file)\n",
    "        b_reader = csv.reader(b_file)\n",
    "    \n",
    "        a_first_row = next(a_reader)\n",
    "        b_first_row = next(b_reader)\n",
    "        intersecting_elements = [element for element in b_first_row if element in a_first_row]\n",
    "        column_indices = [a_first_row.index(element) for element in intersecting_elements]\n",
    "        path_c = os.path.join('models', 'feature.csv')\n",
    "        with open(path_c, 'w', newline='') as c_file:\n",
    "            writer = csv.writer(c_file)\n",
    "            for row in a_reader:\n",
    "                writer.writerow([row[index] for index in column_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_read():\n",
    "    sequences = input_box.get(\"1.0\", \"end\")\n",
    "    new_sequence = sequences.split('\\n')\n",
    "    test_fasta = open(os.path.join(os.getcwd(), \"peptide_sequences.txt\"), 'w+')\n",
    "    for i in range(len(new_sequence)):\n",
    "        if len(new_sequence[i]) == 0:\n",
    "            continue\n",
    "        print('>sequence_%d|0|testing'%(i + 1), file=test_fasta)\n",
    "        print(new_sequence[i], file=test_fasta)\n",
    "    test_fasta.close()\n",
    "\n",
    "    output_box.insert(\"end\", \"Now we have got those peptide sequences.\\n\")\n",
    "    output_box.insert(\"end\", \"Please wait for feature extraction ...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merge():\n",
    "    file_path = os.path.join(os.getcwd(), \"peptide_sequences.txt\")\n",
    "\n",
    "    f_AAC = AAC(file_path)\n",
    "    f_AAC.AAC()\n",
    "    f_AAC.save('AAC.csv')\n",
    "\n",
    "    f_CKSAAP = CKSAAP(file_path)\n",
    "    f_CKSAAP.CKSAAP()\n",
    "    f_CKSAAP.save('CKSAAP.csv')\n",
    "\n",
    "    f_DDE = DDE(file_path)\n",
    "    f_DDE.DDE()\n",
    "    f_DDE.save('DDE.csv')\n",
    "\n",
    "    f_APAAC = APAAC(file_path)\n",
    "    f_APAAC.APAAC()\n",
    "    f_APAAC.save('APAAC.csv')\n",
    "\n",
    "    f_ASDC = ASDC(file_path)\n",
    "    f_ASDC.ASDC()\n",
    "    f_ASDC.save('ASDC.csv')\n",
    "\n",
    "    f_CTDC = CTDC(file_path)\n",
    "    f_CTDC.CTDC()\n",
    "    f_CTDC.save('CTDC.csv')\n",
    "\n",
    "    f_CTDT = CTDT(file_path)\n",
    "    f_CTDT.CTDT()\n",
    "    f_CTDT.save('CTDT.csv')\n",
    "\n",
    "    f_CTDD = CTDD(file_path)\n",
    "    f_CTDD.CTDD()\n",
    "    f_CTDD.save('CTDD.csv')\n",
    "\n",
    "    f_QSO = QSO(file_path)\n",
    "    f_QSO.QSO()\n",
    "    f_QSO.save('QSO.csv')\n",
    "    \n",
    "    FeatureMerge()\n",
    "\n",
    "    file_paths = [\n",
    "        './AAC.csv',\n",
    "        './CKSAAP.csv',\n",
    "        './DDE.csv',\n",
    "        './APAAC.csv',\n",
    "        './ASDC.csv',\n",
    "        './CTDC.csv',\n",
    "        './CTDT.csv',\n",
    "        './CTDD.csv',\n",
    "        './QSO.csv'\n",
    "    ]\n",
    "    for file_path in file_paths:\n",
    "        path = os.path.join(os.getcwd(), file_path)\n",
    "        os.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selection():\n",
    "    data = Analysis()\n",
    "    data.data_import(os.path.join('.', 'Merge.csv'))\n",
    "    data.frame.insert(0, 'Labels', data.label)\n",
    "    data.frame.to_csv(os.path.join('.', 'MergeIG.csv'), sep=',', header=True, index=False)\n",
    "    \n",
    "    i = 1\n",
    "    select(i)\n",
    "    \n",
    "    os.remove(os.path.join('.', 'Merge.csv'))\n",
    "    os.remove(os.path.join('.', 'MergeIG.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(fasta):\n",
    "    test_dir = os.path.join(\".\", \"models\", \"feature.csv\")\n",
    "    fasta.DataLoading(test_dir)\n",
    "    fasta.ModelLoading()\n",
    "    fasta.ModelPrediction()\n",
    "    os.remove(test_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate():\n",
    "    start_time = time.time()\n",
    "\n",
    "    output_box.delete(\"1.0\", \"end\")\n",
    "    \n",
    "    testing_read()\n",
    "    get_merge()\n",
    "    get_selection()\n",
    "    output_box.insert(\"end\", \"Feature extraction successful!\\n\")\n",
    "\n",
    "    fasta = Prediction()\n",
    "    get_result(fasta)\n",
    "\n",
    "    output_box.delete(\"1.0\", \"end\")\n",
    "    output_box.insert(\"end\", \"Here are the result!\\n\")\n",
    "    for i in range(len(fasta.score)):\n",
    "        if(fasta.score[i][0] > fasta.score[i][1]):\n",
    "            output_box.insert(\"end\", \"The sequence_%d is a non-B3PP!\\n\"%(i + 1))\n",
    "        else:\n",
    "            output_box.insert(\"end\", \"The sequence_%d is a B3PP!\\n\"%(i + 1))\n",
    "        output_box.insert(\"end\", \"    The possibility of being a non-B3PP: %.3f\\n\"%(fasta.score[i][0]))\n",
    "        output_box.insert(\"end\", \"    The possibility of being a B3PP: %.3f\\n\"%(fasta.score[i][1]))\n",
    "    \n",
    "    os.remove(os.path.join(\".\", \"peptide_sequences.txt\"))\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(execution_time, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4294030666351318 秒\n"
     ]
    }
   ],
   "source": [
    "root = tk.Tk()\n",
    "root.title(\"Augur\")\n",
    "\n",
    "input_label = tk.Label(root, text=\"Please enter your FASTA sequence：\")\n",
    "input_label.grid(row=0, column=0, sticky=tk.W)\n",
    "input_box = tk.Text(root, height=10, width=50)\n",
    "input_box.grid(row=1, column=0)\n",
    "\n",
    "calculate_button = tk.Button(root, text=\"Predict\", command=calculate)\n",
    "calculate_button.grid(row=4, column=0)\n",
    "\n",
    "output_label = tk.Label(root, text=\"Classification Results：\")\n",
    "output_label.grid(row=2, column=0, sticky=tk.W)\n",
    "output_box = tk.Text(root, height=10, width=50)\n",
    "output_box.grid(row=3, column=0)\n",
    "\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iLearnPlus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
