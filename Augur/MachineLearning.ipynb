{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "import lightgbm\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MachineLearning(object):\n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    "        self.training_dataframe = None\n",
    "        self.training_datalabel = None\n",
    "        self.training_score = None\n",
    "        self.testing_dataframe = None\n",
    "        self.testing_datalabel = None\n",
    "        self.testing_score = None\n",
    "        self.best_model = None\n",
    "        self.best_n_trees = 0\n",
    "        self.metrics = None\n",
    "        self.aucData = None\n",
    "        self.prcData = None\n",
    "        self.meanAucData = None\n",
    "        self.meanPrcData = None\n",
    "        self.indepAucData = None\n",
    "        self.indepPrcData = None\n",
    "        self.algorithm = None\n",
    "        self.error_msg = None\n",
    "        self.boxplot_data = None\n",
    "        self.message = None\n",
    "        self.task = None\n",
    "    \n",
    "    def data_import(self, file):\n",
    "        f = pandas.read_csv(file, sep=',', header=None)\n",
    "        self.training_dataframe = f.iloc[:, 1:]\n",
    "        self.row = self.training_dataframe.index.size\n",
    "        self.column = self.training_dataframe.columns.size\n",
    "        self.training_dataframe.index=['Sample_%s'%i for i in range(self.row)]\n",
    "        self.training_dataframe.columns = ['F_%s'%i for i in range(self.column)]\n",
    "        self.training_datalabel = numpy.array(f.iloc[:, 0]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RF(MachineLearning):\n",
    "    def __init__(self, file):\n",
    "        super(RF, self).__init__(file)\n",
    "\n",
    "    def RF(self):\n",
    "        fold = 5\n",
    "        tree_range = (50, 300, 10)\n",
    "        categories = sorted(set(self.training_datalabel))\n",
    "        X, y = self.training_dataframe.values, self.training_datalabel\n",
    "        best_n_trees = tree_range[0]\n",
    "        best_auc = 0\n",
    "        best_accuracy = 0\n",
    "        best_model = []\n",
    "        best_training_score = None\n",
    "\n",
    "        for tree in range(tree_range[0], tree_range[1] + 1, tree_range[2]):\n",
    "            training_score = numpy.zeros((X.shape[0], len(categories) + 2))\n",
    "            training_score[:, 1] = y\n",
    "            model = []\n",
    "            folds = StratifiedKFold(fold).split(X, y)\n",
    "            for i, (train, valid) in enumerate(folds):\n",
    "                train_X, train_y = X[train], y[train]\n",
    "                valid_X, valid_y = X[valid], y[valid]\n",
    "                rfc_model = RandomForestClassifier(n_estimators=tree, bootstrap=False)\n",
    "                rfc = rfc_model.fit(train_X, train_y)\n",
    "                model.append(rfc)\n",
    "                training_score[valid, 0] = i\n",
    "                training_score[valid, 2:] = rfc.predict_proba(valid_X)\n",
    "\n",
    "            # if len(categories) == 2:\n",
    "            #     metrics= Metrics.getBinaryTaskMetrics(training_score[:, 3], training_score[:, 1])\n",
    "            #     if metrics[6] > best_auc:\n",
    "            #         best_auc = metrics[6]\n",
    "            #         best_n_trees = tree\n",
    "            #         best_model = model\n",
    "            #         best_training_score = training_score\n",
    "            # if len(categories) > 2:\n",
    "            #     metrics = Metrics.getMutiTaskMetrics(training_score[:, 2:], training_score[:, 1])\n",
    "            #     if metrics[0] > best_accuracy:\n",
    "            #         best_accuracy = metrics[0]\n",
    "            #         best_n_trees = tree\n",
    "            #         best_model = model\n",
    "            #         best_training_score = training_score\n",
    "        \n",
    "        self.training_score = pandas.DataFrame(best_training_score, columns=['Fold', 'Label'] + ['Score_%s' %i for i in categories])\n",
    "        self.best_model = best_model\n",
    "        self.best_n_trees = best_n_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGBM(MachineLearning):\n",
    "    def __init__(self, file):\n",
    "        super(LightGBM, self).__init__(file)\n",
    "\n",
    "    def LightGBM(self):\n",
    "        fold = 5\n",
    "        type = 'gbdt'\n",
    "        parameters = {\n",
    "            'num_leaves': list(range(20, 100, 10)),\n",
    "            'max_depth': list(range(15, 55, 10)),\n",
    "            'learning_rate': list(numpy.arange(0.01, 0.15, 0.02))\n",
    "        }\n",
    "        gbm = lightgbm.LGBMClassifier(boosting_type=type)\n",
    "        gsearch = GridSearchCV(gbm, param_grid=parameters).fit(self.training_dataframe.values, self.training_datalabel)\n",
    "        best_parameters = gsearch.best_params_\n",
    "        num_leaves = best_parameters['num_leaves']\n",
    "        max_depth = best_parameters['max_depth']\n",
    "        learning_rate = best_parameters['learning_rate']\n",
    "\n",
    "        categories = sorted(set(self.training_datalabel))\n",
    "        X, y = self.training_dataframe.values, self.training_datalabel\n",
    "        training_score = numpy.zeros((X.shape[0], len(categories) + 2))\n",
    "        training_score[:, 1] = y\n",
    "        model = []\n",
    "        folds = StratifiedKFold(fold).split(X, y)\n",
    "        for i, (train, valid) in enumerate(folds):\n",
    "            train_X, train_y = X[train], y[train]\n",
    "            valid_X, valid_y = X[valid], y[valid]\n",
    "            gbm_model = lightgbm.LGBMClassifier(boosting_type=type, num_leaves=num_leaves, max_depth=max_depth, learning_rate=learning_rate).fit(train_X, train_y)\n",
    "            model.append(gbm_model)\n",
    "            training_score[valid, 0] = i\n",
    "            training_score[valid, 2:] = gbm_model.predict_proba(valid_X)\n",
    "        self.training_score = pandas.DataFrame(training_score, columns=['Fold', 'Label'] + ['Score_%s' %i for i in categories])\n",
    "        self.best_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR(MachineLearning):\n",
    "    def __init__(self, file):\n",
    "        super(LR, self).__init__(file)\n",
    "    \n",
    "    def LR(self):\n",
    "        categories = sorted(set(self.training_datalabel))\n",
    "        X, y = self.training_dataframe.values, self.training_datalabel\n",
    "        training_score = numpy.zeros((X.shape[0], len(categories) + 2))\n",
    "        training_score[:, 1] = y\n",
    "        model = []\n",
    "        folds = StratifiedKFold(fold).split(X, y)\n",
    "        for i, (train, valid) in enumerate(folds):\n",
    "            train_X, train_y = X[train], y[train]\n",
    "            valid_X, valid_y = X[valid], y[valid]\n",
    "            lr_model = LogisticRegression(C=1.0, random_state=0).fit(train_X, train_y)\n",
    "            model.append(lr_model)\n",
    "            training_score[valid, 0] = i\n",
    "            training_score[valid, 2:] = lr_model.predict_proba(valid_X)\n",
    "        self.training_score = pandas.DataFrame(training_score, columns=['Fold', 'Label'] + ['Score_%s' %i for i in categories])\n",
    "        self.best_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM(MachineLearning):\n",
    "    def __init__(self, file):\n",
    "        super(SVM, self).__init__(file)\n",
    "    \n",
    "    def SVM(self):\n",
    "        kernel = 'poly'\n",
    "        fold = 5\n",
    "        gamma = 1/self.training_dataframe.values.shape[1]\n",
    "        penalityRange = (0.1, 15, 0.1)\n",
    "        parameters = {'kernel': [kernel], 'C': penalityRange, 'gamma': 2.0 ** numpy.arange(0.001, 10)}\n",
    "\n",
    "        optimizer = GridSearchCV(svm.SVC(probability=True), parameters).fit(self.training_dataframe.values, self.training_datalabel)\n",
    "        params = optimizer.best_params_\n",
    "        penality = params['C']\n",
    "        gamma = params['gamma']\n",
    "\n",
    "        categories = sorted(set(self.training_datalabel))\n",
    "        X, y = self.training_dataframe.values, self.training_datalabel\n",
    "        training_score = numpy.zeros((X.shape[0], len(categories) + 2))\n",
    "        training_score[:, 1] = y\n",
    "        model = []\n",
    "        folds = StratifiedKFold(fold).split(X, y)\n",
    "        for i, (train, valid) in enumerate(folds):\n",
    "            train_X, train_y = X[train], y[train]\n",
    "            valid_X, valid_y = X[valid], y[valid]\n",
    "            svm_model = svm.SVC(C=penality, kernel=kernel, degree=3, gamma=gamma, coef0=0.0, shrinking=True, probability=True, random_state=1)\n",
    "            svc = svm_model.fit(train_X, train_y)\n",
    "            model.append(svc)\n",
    "            training_score[valid, 0] = i\n",
    "            training_score[valid, 2:] = svc.predict_proba(valid_X)\n",
    "        self.training_score = pandas.DataFrame(training_score, columns=['Fold', 'Label'] + ['Score_%s' %i for i in categories])\n",
    "        self.best_model = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN(MachineLearning):\n",
    "    def __init__(self, file):\n",
    "        super(KNN, self).__init__(file)\n",
    "    \n",
    "    def KNN(self):\n",
    "        fold = 5\n",
    "        n_neighbors = 3\n",
    "\n",
    "        categories = sorted(set(self.training_datalabel))\n",
    "        X, y = self.training_dataframe.values, self.training_datalabel\n",
    "        training_score = numpy.zeros((X.shape[0], len(categories) + 2))\n",
    "        training_score[:, 1] = y\n",
    "        model = []\n",
    "        folds = StratifiedKFold(fold).split(X, y)\n",
    "        for i, (train, valid) in enumerate(folds):\n",
    "            train_X, train_y = X[train], y[train]\n",
    "            valid_X, valid_y = X[valid], y[valid]\n",
    "            knn_model = KNeighborsClassifier(n_neighbors=n_neighbors).fit(train_X, train_y)\n",
    "            model.append(knn_model)\n",
    "            training_score[valid, 0] = i\n",
    "            training_score[valid, 2:] = knn_model.predict_proba(valid_X)\n",
    "        self.training_score = pandas.DataFrame(training_score, columns=['Fold', 'Label'] + ['Score_%s' %i for i in categories])\n",
    "        self.best_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_path = os.path.join('.', 'training.csv')\n",
    "f = MachineLearning(f_path)\n",
    "f.data_import(f_path)\n",
    "#f.RF()\n",
    "#f.SVM()\n",
    "#f.LR()\n",
    "#f.LightGBM()\n",
    "#f.KNN()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iLearnPlus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
